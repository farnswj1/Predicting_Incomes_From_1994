---
title: "Predicting Incomes From 1994"
author: "Justin Farnsworth"
date: "6/15/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Summary
In this project, a sample of the US population, originally from the 1994 Census, was taken and analyzed in an effort to generate an algorithm that could accurately predict whether an individual made over \$50,000 or not. The variables that were used to predict income included but were not limited to age, race, sex, education, occupation, hours per week, and marital status.

Before generating numerous algorithms, an exploration of the dataset was conducted to identify patterns that could be useful when predicting income. We identified groups that were most likely to make over \$50,000 based on the data.

A total of six machine learning algorithms were used to predict income. Five of the models were supervised learning models and the final model was an ensemble of the supervised learning models. It was determined that the **stochastic gradient boosting (GBM)** model performed the best, with an **accuracy of 86.18%**. The ensemble also did comparatively well as it had an accuracy of 86.10%. Across all models, they were all capable of correctly predicting those who make \$50,000 or less most of the time. However, they all struggled with correctly predicting those who made more than \$50,000.

Each section has their methods and models explained, followed by their respective results. 

The dataset can be accessed here:
<https://www.kaggle.com/uciml/adult-census-income/data>

A copy of the dataset is also present in the project's GitHub repository:
<https://github.com/farnswj1/Predicting_Incomes_From_1994.git>


# Analysis
An exploration of the dataset was conducted to identify patterns/relationships in the dataset.

```{r load_dataset, message = FALSE}
# Required packages
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(gghighlight)) install.packages("gghighlight", repos = "http://cran.us.r-project.org")
if(!require(gbm)) install.packages("gbm", repos = "http://cran.us.r-project.org")
if(!require(mda)) install.packages("mda", repos = "http://cran.us.r-project.org")
if(!require(earth)) install.packages("earth", repos = "http://cran.us.r-project.org")
if(!require(tinytex)) install.packages("tinytex", repos = "http://cran.us.r-project.org")

# Create a temporary file and load the dataset into it
# NOTE: The CSV is already on this project's GitHub repo.
# Original Source: https://www.kaggle.com/uciml/adult-census-income/data
datafile = tempfile()
download.file(
  "https://raw.github.com/farnswj1/Predicting_Incomes_From_1994/master/adult.csv", 
  datafile
)

# Read the data from the file
data <- read.csv(datafile)

# Delete the temporary file
rm(datafile)
```

## Exploring the Dataset - Overview
After loading the dataset, we saw that there were `r nrow(data)` rows (each row represented a person) and `r ncol(data)` columns. Here were the first 10 rows of the dataset:

```{r show_data_head}
# Show the first 10 rows of the dataset
head(data, 10)
```

We saw that there were missing values for some of the rows, which were represented as `?`. However, we checked to see if there are any null values (NA).

```{r check_for_null_values}
# Check if any values in the table are null
any(is.na(data))
```

It seemed that the dataset is fairly clean despite some unknown values. We then checked to see what the datatypes were for each column.

```{r show_column_datatypes}
# Show column names and their datatypes
data.frame(
  column_names = colnames(data),
  data_type = map_chr(colnames(data), function(colname) {class(data[,colname])})
)
```


## Exploring the Dataset - Age
We began by identifying the range of ages that the dataset consisted of.

```{r show_age_range}
# Find the range of age values in the dataset
range(data$age)
```

Given the wide range of ages, it might be more helpful to visualize the prevalance of each age group in the dataset. The following graph shows the total number of people for each age group.

```{r plot_age_count, message = FALSE}
# Calculate the number of people and 
# the percentage of people who made >$50k for each age
data_age_groups <- data %>% 
  group_by(age) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100)

# Plot the number of people in the dataset by age.
data_age_groups %>% 
  ggplot(aes(age, total)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Number of Adults by Age") + 
  xlab("Age") + 
  ylab("Total") + 
  scale_x_continuous(labels = seq(20, 90, 10), breaks = seq(20, 90, 10)) + 
  scale_y_continuous(labels = seq(0, 1000, 200), breaks = seq(0, 1000, 200))
```

As expected, the most prevalent age groups in the dataset were younger. It appeared to peak in the mid-30s, then it declined afterwards. However, we identified the percentage of people who made over \$50,000 for each age group.

```{r plot_age_percentages, message = FALSE}
# Plot the percentage of people what made over $50k by age
data_age_groups %>%
  ggplot(aes(age, percentage)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Age") + 
  xlab("Age") + 
  ylab("Percentage") +
  scale_x_continuous(labels = seq(20, 90, 10), breaks = seq(20, 90, 10))
```

Interestingly, those that were about 50 years old were most likely to make over $50,000. We saw that there was a high percentage for specific age groups over 75. However, the prevalence of those over 75 years old wasn't as high.

```{r show_age_75_and_over, message = FALSE}
# Show the number of adults in the dataset that are over 75 by age
data_age_groups %>% 
  group_by(age) %>% 
  filter(age > 75) %>% 
  select(total)
```


## Exploring the Dataset - Work Class
Here were the different work classes in the dataset:

```{r show_workclasses}
# Show the different types of work classes
unique(data$workclass)
```

As mentioned previously, we saw the `?` was listed as one of the values. However, we observed the total number of people for each work class in the dataset as well as their percentages:

```{r show_workclass_count_percentage}
# Show the percentages and total number of people
data_work_classes <- data %>% 
  group_by(workclass) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage))

data_work_classes
```

Unsurprisingly, those who never worked or aren't getting paid were not going to have high percentages. They were not receiving income and so they were almost certainly not going to earn over \$50,000.

We also saw that the private work class made up the majority of people in the dataset. To visualize the prevalence of the work class, the following graph shows the total number of people in each work class:

```{r plot_workclass_count, message = FALSE}
# Plot the total number of people from each work class
data_work_classes %>% 
  mutate(workclass = reorder(workclass, total)) %>% 
  ggplot(aes(workclass, total)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Number of People by Work Class") + 
  xlab("Work Class") + 
  ylab("Total") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

We then observed the percentage of people who made over \$50,000 for each work class:

```{r plot_workclass_percentage, message = FALSE}
# Plot the percentage of people what made over $50k by work class
data_work_classes %>% 
  mutate(workclass = reorder(workclass, percentage)) %>% 
  ggplot(aes(workclass, percentage)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Work Class") +  
  xlab("Work Class") + 
  ylab("Percentage") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  scale_y_continuous(labels = seq(0, 60, 10), breaks = seq(0, 60, 10))
```

Note that the private work class didn't have the highest percentage despite the high prevlance. Instead, it appeared that those who were classified as part of the public sector or self-employed incorporated had the highest percentages. Particularly, the self-employed incorporated work class were twice as more likely than the private work class to make over than \$50,000.


## Exploring the Dataset - Education
Here were the different levels of education in the dataset:

```{r show_education_count_percentage}
# Show the different levels of education along with the totals and percentages
data_education <- data %>% 
  select(education, education.num, income) %>% 
  group_by(education.num, education) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(education.num)) %>% 
  ungroup()

data_education
```

It was expected that those who have a higher level of education tend to have a better chance of making more money. Despite the wide range of levels of education, we saw that the most common level of education was a high school graduate. A visualization of the total number of people for each level of education is shown as follows:

```{r plot_education_count, message = FALSE}
# Plot the number of people for each level of education
data_education %>% 
  mutate(education = reorder(education, education.num)) %>% 
  ggplot(aes(education, total)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Number of People by Level of Education") + 
  xlab("Level of Education") + 
  ylab("Total") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

However, the percentages are visualized in the following:

```{r plot_education_percentage, message = FALSE}
# Plot the percentage of people what made over $50k by level of education
data_education %>% 
  mutate(education = reorder(education, education.num)) %>% 
  ggplot(aes(education, percentage)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Work Class") +  
  xlab("Level of Education") + 
  ylab("Percentage") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  scale_y_continuous(labels = seq(0, 80, 10), breaks = seq(0, 80, 10))
```


## Exploring the Dataset - Marital & Relatiionship Status
The following shows the total number of people in each category as well as the percentage of people who made over \$50,000 for each group:

```{r show_marital_status_count_percentage}
# Show the total number of people and the percentage of 
# people that made over $50k by marital status
data %>% 
  group_by(marital.status) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage))
```

The dataset suggested that those who were married had a significantly higher percentage than those that were not married. In fact, the percentage was 4 times higher than the next category, Divorced.

We then examined the relationship statuses next:

```{r show_relationship_count_percentage}
# Show the total number of people and the percentage of 
# people that made over $50k by relationship status
data %>% 
  group_by(relationship) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage))
```

This was consistent with the findings from the marital status column. Those that were married had a much higher probability of making over \$50,000.


## Exploring the Dataset - Occupation
We analyzed the different occupational types.

```{r show_occupation_count_percentage}
# Show the number of people in each type of occupation along with the 
# percentage of people who made over $50k for each occupation type.
data_occupations <- data %>% 
  group_by(occupation) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage))

data_occupations
```

The occupational type by percentage was executive management, which was also one of the most prevalent types in the dataset. The only occupational type that remained under 1% was private house services. A visualization of the table is shown as follows:

```{r plot_occupation_percentage, message = FALSE}
# Plot the percentage of people what made over $50k by level of education
data_occupations %>% 
  mutate(occupation = reorder(occupation, percentage)) %>% 
  ggplot(aes(occupation, percentage)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Occupational Type") +  
  xlab("Occupational Type") + 
  ylab("Percentage") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  scale_y_continuous(labels = seq(0, 80, 10), breaks = seq(0, 80, 10))
```


## Exploring the Dataset - Race & Sex
The dataset also included information about the individual's race and sex. We analyzed race first.

Here were the total of number of people for each group as well as their percentages:

```{r show_race_count_percentage}
# Show the totals and percentages for each racial group
data_races <- data %>% 
  group_by(race) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage))

data_races
```

While the majority of the people in the dataset were white, those of Asian/Pacific Islander descent had the highest percentage. The dataset suggested that those who were white or Asian/Pacific Islander were twice as likely to make over \$50,000 than those that were black or American-Indian/Eskimo.

Here is the analysis the sexes:

```{r show_sex_count_percentage}
# Show the totals and percentages for males and females
data_sexes <- data %>% 
  group_by(sex) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage))

data_sexes
```

Men had almost triple the likelihood of making more than \$50,000 when compared to women. However, the reason for this observation was not clearly explained by the dataset.

Next, we analyzed the two features together:

```{r show_race_and_sexes_count_percentage}
# Show the totals and percentages by race and sex together
data_races_and_sexes <- data %>% 
  group_by(race, sex) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(percentage)) %>% 
  ungroup()

data_races_and_sexes
```

Across all races, men had a higher probability of earning more than \$50,000 than women of the same race. It was also suggested by the data that some groups had a higher percentage than women of all racial groups. The only male group that didn't was those listed as Other.

A plot of the table above is shown below:

```{r plot_race_sex_percentage, message = FALSE}
# Plot the percentages by race and sex
data_races_and_sexes %>% 
  mutate(race = reorder(race, percentage)) %>% 
  ggplot(aes(race, percentage, fill = sex)) + 
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Race and Sex") +  
  xlab("Race") + 
  ylab("Percentage") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

NOTE: We do NOT encourage discrimination on the basis of race, sex, or any other immutable characteristic.


## Exploring the Dataset - Capital
The dataset provided two columns: capital gains and capital losses. We used this information to calculate net capital gains, which is defined as:

$$net\ capital\ gain = capital\ gain - capital\ loss$$

We also rounded the net capital gains for each row to the nearest thousand.

```{r show_net_capital_gains_count_percentage}
# Show the totals and percentages by net capital gains (rounded to the nearest 1000)
data_net_capital_gains <- data %>%
  mutate(net_capital_gain = round((capital.gain - capital.loss) / 1000) * 1000) %>% 
  group_by(net_capital_gain) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(net_capital_gain))

data_net_capital_gains %>% print(n = Inf)
```

Most people in the dataset had a net capital gain of 0. In other words, they either made or lost some money through their capital or they didn't have financial assets in 1994.

It was also no surprise that those who made over \$50,000 in net capital gains had a 100% probability of having an income listed as more than \$50,000. This was because they already earned more than \$50,000 in net capital gains alone.

We also saw a small number of people had a negative net capital gains. One user managed to make more than \$50,000 for the year despite losing nearly \$4,000! Also, most people who lost about \$2,000 - \$3,000 still made more than \$50,000 that year. 
Here is the plot of the percentages by net capital gains:

```{r plot_net_capital_gains_percentage, message = FALSE}
# Plot the percentages by net capital gain
data_net_capital_gains %>% 
  filter(net_capital_gain <= 50000) %>%
  ggplot(aes(net_capital_gain, percentage)) + 
  geom_bar(stat = "identity") + 
  geom_point() + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Net Capital Gains") +  
  xlab("Net Capital Gain") + 
  ylab("Percentage")
```


## Exploring the Dataset - Hours Per Week
Intuitively, the more hours one worked each week, the more money one made. Below is the percentage of people who made over \$50,000 by the number of hours per week:

```{r plot_hours_per_week_percentage, message = FALSE}
# Plot the percentage of people who made over $50k by weekly hours
data %>% 
  group_by(hours.per.week) %>% 
  summarize(percentage = mean(income == ">50K") * 100) %>% 
  ggplot(aes(hours.per.week, percentage)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Weekly Hours") +  
  xlab("Hours Per Week") + 
  ylab("Percentage") + 
  scale_x_continuous(labels = seq(0, 100, 10), breaks = seq(0, 100, 10))
```

As expected, those who worked more hours were more likely to have made more than \$50,000 and vice versa.


## Exploring the Dataset - Native Country
Here were the totals and percentages by country of origin:

```{r show_native_country_count_percentage}
# Show total and percentages by native country
data_native_countries <- data %>% 
  group_by(native.country) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100) %>% 
  arrange(desc(total))

data_native_countries %>% print(n = Inf)
```

As expected, most people in the dataset were born in the US. However, people from particular countries were more likely to make over \$50,000. For example, Germany, Canada, and Cuba. A plot of the percentages for each country is shown below:

```{r plot_native_country_percentage, message = FALSE}
# Plot the percentages by country
data_native_countries %>% 
  mutate(native.country = reorder(native.country, percentage)) %>% 
  ggplot(aes(native.country, percentage)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Native Country") +  
  xlab("Country") + 
  ylab("Percentage") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  gghighlight(native.country == "United-States")
```

We observed that those born in the US were not the most likely to make more than \$50,000. Out of the countries listed in the dataset, the US sat somewhere in the middle. The countries with the highest percentages were Iran, France, and India.

We also observed that some countries are listed as having a 0% probabaility of making over \$50,000. This was not (and is not) representative of immigrants of those countries collectively, as the data didn't have a large prevalence of people from those countries.

```{r show_native_countries_count_bottom_10}
# Show the native countries with the least amount of adults in the dataset
data_native_countries %>% 
  arrange(total) %>% 
  head(10)
```

Only 1 person from the Netherlands was in the dataset and that person didn't make over \$50,000. We also saw that people from countries such as Cambodia and Yugoslavia had a small prevlance as well, but in particular, they had a higher percentage.

We analyzed the column based on whether the person was born in the US or not. Here are the totals and percentages for both groups:

```{r show_US_born_count_percentage}
# Show the totals and percentages based on whether the adult is born in the US
data_us_born <- data %>% 
  mutate(
    is_US_born = factor(
      ifelse(native.country == "United-States", "Born in the US", "Not Born in the US")
    )
  ) %>% 
  group_by(is_US_born) %>% 
  summarize(total = n(), percentage = mean(income == ">50K") * 100)
data_us_born
```

The dataset suggested that nearly 10% of people in the US were born in another country. Also, US citizens had a higher probability of making over \$50,000, but by nearly 5% more.

A visualization of percentages from the table above is shown below:

```{r plot_US_born_percentage, message = FALSE}
# Plot the percentages based on whether the adult is born in the US
data_us_born %>% 
  ggplot(aes(is_US_born, percentage, fill = is_US_born)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Percentage of Adults That Made Over $50,000 by Native Status") +  
  xlab("Country") + 
  ylab("Percentage") + 
  labs(fill = "Native Status")
```


## Exploring the Dataset - Final Weight
The dataset also provided a column called `fnlwgt`, or final weight. According to Ronny Kohavi and Barry Becker (see <https://www.kaggle.com/uciml/adult-census-income/data>), people from similar demographics should have had similar final weight values. Due to the complexity of this calculation, we just compared the distribution of final weights of those who made over \$50,000 to the distribtuion of final weights of those that didn't.

```{r show_final_weight_distribution}
# Calculate the mean, standard error, and total number of the final weights by income
data_final_weights <- data %>% 
  group_by(income) %>% 
  summarize(total = n(), 
            proportion = n()/nrow(data), 
            avg = mean(fnlwgt), 
            se = sd(fnlwgt)/sqrt(n()), 
            conf_low = avg - 2 * se, 
            conf_high = avg + 2 * se)

data_final_weights
```

A visualization of the distributions above is shown below:

```{r plot_final_weight_distribution, message = FALSE}
# Plot the mean and confidence intervals of the final weights by income
data_final_weights %>% 
  ggplot(aes(income, avg, ymin = avg - 2 * se, ymax = avg + 2 * se)) + 
  geom_point() +
  geom_errorbar() + 
  ggtitle("Disribution of Final Weights By Income Classification") +  
  xlab("Income") + 
  ylab("Final Weight")
```

While there was some overlap, we saw that the averages were outside each other's confidence intervals.


# Models
In this section, we used the features to generate models that can accurately predict the user's income classification. We used the logistic regression, stochastic gradient boosting (GBM), flexible discriminant analysis (FDA), classification tree, random forest, and ensemble models in an effort to predict the incomes.


## Models - Preparing the Dataset
Before continuing, we added a net capital gains column and removed columns that were redundant, such as education number, capital gains, and capital losses.

```{r process_dataset, message = FALSE}
# Generate the net capital gains column.
# Then remove the columns that won't be used for the models
data <- data %>% 
  mutate(net_capital_gain = as.numeric(capital.gain - capital.loss)) %>% 
  select(-c(education.num, capital.gain, capital.loss))
```


## Models - Training & Test Sets
For this project, we split the dataset into a training set, which consisted of 80% of the rows, and a test set, which consisted of the remaining 20%. This provided enough test cases to determine accuracy while providing enough training data for the models.

```{r generate_train_and_test_sets, message = FALSE, warning = FALSE}
# Split the data into a training set (80%) and a test set (20%)
set.seed(1, sample.kind = "Rounding")
test_index <- createDataPartition(data$income, times = 1, p = 0.2, list = FALSE)
train_set <- data[-test_index,]
test_set <- data[test_index,]
rm(test_index)
```

The proportion of incomes less than or equal to \$50,000 in the training set and test set was `r mean(train_set$income == "<=50K")` and `r mean(test_set$income == "<=50K")` respectively. Both sets had about the same proportion of income types.

For our baseline model, we assumed that everyone made under \$50,000. While we would achieve an accuracy of `r mean(test_set$income == "<=50K") * 100`%, we would have specificity of 0%. In other words, everyone who made over \$50,000 would be incorrectly predicted to have made \$50,000 or less.


## Models - Logistic Regression
The first model used was the logistic regression model, which was an improvement over the baseline model. However, it could be improved. The following code generates the model, makes the predictions, and displays the results.

```{r glm, message = FALSE, warning = FALSE}
# Train the model
set.seed(1, sample.kind = "Rounding")
train_glm <- train(income ~ ., 
                   method = "glm", 
                   data = train_set)

# Make the predictions
y_hat_glm <- predict(train_glm, test_set)

# Determine accuracy of the model
results_glm <- confusionMatrix(data = y_hat_glm, reference = test_set$income)
results_glm
```


## Models - Stochastic Gradient Boosting (GBM)
After the logistic model, we then tried using a stochastic gradient boosting, or GBM, to predict the incomes. We saw that all metrics were improved using this model. The following code generates the model, makes the predictions, and displays the results.

```{r gbm, message = FALSE, warning = FALSE, results = "hide"}
# Train the model
set.seed(1, sample.kind = "Rounding")
train_gbm <- train(income ~ ., 
                   method = "gbm", 
                   data = train_set)
```

Note that a lot of output is generated when fitting the model. 

```{r gbm_continued, message = FALSE, warning = FALSE}
# Make the predictions
y_hat_gbm <- predict(train_gbm, test_set)

# Determine accuracy of the model
results_gbm <- confusionMatrix(data = y_hat_gbm, reference = test_set$income)
results_gbm
```


## Models - Flexible Discriminant Analysis (FDA)
Using flexible discriminant analysis (FDA), we didn't see any improvements. Instead, the model performs worse than the previous models used. However, the model managed to achieve an accuracy over 80%. The following code generates the model, makes the predictions, and displays the results.

```{r fda, message = FALSE, warning = FALSE}
# Train the model
set.seed(1, sample.kind = "Rounding")
train_fda <- train(income ~ ., 
                   method = "fda", 
                   data = train_set, 
                   tuneGrid = data.frame(degree = 1, nprune = seq(21, 30, 2)))

# Make the predictions
y_hat_fda <- predict(train_fda, test_set)

# Determine accuracy of the model
results_fda <- confusionMatrix(data = y_hat_fda, reference = test_set$income)
results_fda
```

We observed the optimal parameter values used as well as the accuracies obtained for each value. The degree value was set to 1, however the optimal value for `nprune` was `r train_fda$bestTune[,"nprune"]`.

```{r fda_tunes}
# Plot the model's accuracy for each complexity parameter
plot(train_fda, main = "Flexible Discriminant Analysis Results", xlab = "Number of Terms")

# Show the most optimal paramater value
train_fda$bestTune
```

## Models - Classification Tree
The classification tree performed well, but there were no improvements to the accuracy. Despite this, it still performed better than the FDA model. The following code generates the model, makes the predictions, and displays the results.

```{r ct, message = FALSE, warning = FALSE}
# Train the model
set.seed(1, sample.kind = "Rounding")
train_ct <- train(income ~ ., 
                  method = "rpart", 
                  data = train_set, 
                  tuneGrid = data.frame(cp = seq(0, 0.01, 0.001)))

# Make the predictions
y_hat_ct <- predict(train_ct, test_set)

# Determine accuracy of the model
results_ct <- confusionMatrix(data = y_hat_ct, reference = test_set$income)
results_ct
```

We identified the optimal parameter value used and compared the accuracy obtained from that value to accuracies from other parameter values.

```{r ct_tunes}
# Plot the model's accuracy for each complexity parameter
plot(train_ct, main = "Classification Tree Results")

# Show the most optimal paramater value
train_ct$bestTune

```

We see that the best complexity paramater value was `r train_ct$bestTune[,"cp"]`. 

We were also able to identity the most important variables used in this model. We saw that `net_capital_gain` was the most important variable.

```{r ct_varimp}
# Show the most important variables in the model
varImp(train_ct)
```


## Models - Random Forest
After seeing the results of the classification tree, it was worth trying the random forest model to see if the accuracy improved even more. However, it was an improvement over the classification tree by nearly 1%. Using 100 trees, we saw the model achieved an accuracy slightly over 86%. The following code generates the model, makes the predictions, and displays the results.

```{r rf, message = FALSE, warning = FALSE}
# Train the model
# NOTE: This will take roughly 45 minutes to complete
set.seed(1, sample.kind = "Rounding")
train_rf <- train(income ~ ., 
                  method = "rf", 
                  data = train_set, 
                  ntree = 100, 
                  tuneGrid = data.frame(mtry = 10), 
                  importance = TRUE)

# Make the predictions
y_hat_rf <- predict(train_rf, test_set)

# Determine accuracy of the model
results_rf <- confusionMatrix(data = y_hat_rf, reference = test_set$income)
results_rf
```

Here were the most important variables for this model. We saw that `net_capital_gain` was listed as the most important variable in the model, followed by marital status, age, education, occupation, and hours per week.

```{r rf_varimp}
# Show the most important variables in the model
varImp(train_rf)
```


## Models - Ensemble
Using the previous models, we used the predictions generated from each of the models to predict the incomes. It managed to achieve an accuracy of 86.10%. The following code generates the model, makes the predictions, and displays the results.

```{r ensemble}
# Create the ensemble
ensemble <- data.frame(glm = y_hat_glm,
                       gbm = y_hat_gbm,
                       fda = y_hat_fda,
                       ct = y_hat_ct,
                       rf = y_hat_rf)

# Make the predictions
y_hat_ensemble <- factor(ifelse(rowMeans(ensemble == ">50K") > 0.5, ">50K", "<=50K"))

# Determine accuracy of the model
results_ensemble <- confusionMatrix(data = y_hat_ensemble, reference = test_set$income)
results_ensemble
```


# Results
We condensed the results of all the models into a table, where we compared the models.

```{r results}
# Save the model names
models <- c(
  "Logistic Regression", 
  "GBM", 
  "FDA", 
  "Classification Tree", 
  "Random Forest", 
  "Ensemble"
)

# Save the model accuracies
accuracies <- c( 
  mean(test_set$income == y_hat_glm), 
  mean(test_set$income == y_hat_gbm), 
  mean(test_set$income == y_hat_fda), 
  mean(test_set$income == y_hat_ct), 
  mean(test_set$income == y_hat_rf), 
  mean(test_set$income == y_hat_ensemble)
)

# Save the model sensitivities
sensitivities <- c(
  sensitivity(data = y_hat_glm, reference = test_set$income), 
  sensitivity(data = y_hat_gbm, reference = test_set$income), 
  sensitivity(data = y_hat_fda, reference = test_set$income), 
  sensitivity(data = y_hat_ct, reference = test_set$income), 
  sensitivity(data = y_hat_rf, reference = test_set$income), 
  sensitivity(data = y_hat_ensemble, reference = test_set$income)
) 

# Save the model specificities
specificities <- c(
  specificity(data = y_hat_glm, reference = test_set$income), 
  specificity(data = y_hat_gbm, reference = test_set$income), 
  specificity(data = y_hat_fda, reference = test_set$income), 
  specificity(data = y_hat_ct, reference = test_set$income), 
  specificity(data = y_hat_rf, reference = test_set$income), 
  specificity(data = y_hat_ensemble, reference = test_set$income)
) 

# Save the model precision
precisions <- c(
  precision(data = y_hat_glm, reference = test_set$income), 
  precision(data = y_hat_gbm, reference = test_set$income), 
  precision(data = y_hat_fda, reference = test_set$income), 
  precision(data = y_hat_ct, reference = test_set$income), 
  precision(data = y_hat_rf, reference = test_set$income), 
  precision(data = y_hat_ensemble, reference = test_set$income)
) 

# Save the model F1 scores
F1s <- c(
  F_meas(data = y_hat_glm, reference = test_set$income), 
  F_meas(data = y_hat_gbm, reference = test_set$income), 
  F_meas(data = y_hat_fda, reference = test_set$income), 
  F_meas(data = y_hat_ct, reference = test_set$income), 
  F_meas(data = y_hat_rf, reference = test_set$income), 
  F_meas(data = y_hat_ensemble, reference = test_set$income)
) 

# Combine the results into a data frame, then display them
results <- data.frame(
  Model = models, 
  Accuracy = accuracies, 
  Sensitivity = sensitivities, 
  Specificity = specificities, 
  Precision = precisions, 
  F1 = F1s
)

results
```

We saw that the **GBM** model had the highest accuracy, sensitivity, and F1 score. The accuracy of the model was **86.18%**. The random forest model had the highest specificity and was the only model to achieve a specificity of 60%. The random forest model also had the highest precision, but it had one of lowest sensitivites. We also observed that the FDA model didn't perform as as well in most metrics.

The following graph shows the accuracies of all the models and how they compared to the baseline model (`r mean(test_set$income == "<=50K")`). All models performed better than the baseline model and the differences between the accuracies were small.

```{r plot_accuracies}
# Plot the accuracies of each model
results %>% 
  mutate(Model = reorder(Model, Accuracy)) %>%
  ggplot(aes(Model, Accuracy)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Model Results vs. Baseline Model (Green Line)") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  geom_hline(yintercept = mean(test_set$income == "<=50K"), color = "green") + 
  scale_y_continuous(labels = seq(0, 1, 0.1), breaks = seq(0, 1, 0.1))
```

The most variability observed from the results was from specificity. The range of values extended from about 54.3% to about 60.7%, a 6.4% difference! The graph below visualizes the specificities for all the models.

```{r plot_specificities}
# Plot the specificities of each model
results %>% 
  mutate(Model = reorder(Model, Specificity)) %>%
  ggplot(aes(Model, Specificity)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Specificity of the Models") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  scale_y_continuous(labels = seq(0, 1, 0.1), breaks = seq(0, 1, 0.1))
```


# Conclusion
It was discovered that people who were about 50 years old had the highest probability of making over \$50,000 than the other age groups. It also seemed that people who had government jobs or were self-employed incorporated had a better chance of making more money than those in the private sector. Surprisingly, the dataset suggested that men had a higher probability of making over \$50,000 than women, although the reason behind this was unclear. It is also noted that those of Asian/Pacific Island descent had the highest probability despite having a small prevalance. Another surprising observation was that US citizens didn't have the highest probability. The top 3 probabilities by ethnic groups were Iranian, French, and Indian.

When predicting the incomes, the stochastic gradient boosting model performed the best overall. Based on the classification tree and random forest models, it was determined that net capital gain was the most important variable when predicting incomes. Education, occupation, age, hours per week, and marital status were also among one of the most important variables as well. Immutable characteristics such as race and sex were not considered to be as important, according to both models.

The findings indicate that personal choices are one of the biggest determinants of income. Those that pursued a higher education, were married, worked more hours, worked in higher-paying occupations, and invested in capital were more likely to earn over \$50,000 in 1994.

An important note to consider is that the data is over 25 years old. However, it is likely that these observations can still be utilized and applied today. For instance, investing, pursuing a higher education and working more hours all can improve one's chances of making more than \$50,000.